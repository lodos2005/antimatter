# LLM Provider Mode (AI Model Provider)

[TÃ¼rkÃ§e Versiyonu Ä°Ã§in AÅŸaÄŸÄ± KaydÄ±rÄ±n](#llm-provider-modu-model-saÄŸlayÄ±cÄ±)

---

## English ğŸ‡¬ğŸ‡§

**LLM Provider** mode enables Antimatter to function as a standard **OpenAI-Compatible API**. In this mode, Antimatter receives chat requests, processes them using the Google Gemini API in the background, and returns the response in the OpenAI format.

This allows you to use Gemini models with hundreds of applications that don't natively support Google Gemini but support OpenAI.

### Features

*   **OpenAI Compatibility:** Provides `/v1/chat/completions` and `/v1/models` endpoints.
*   **Account Rotation:** Use multiple Google accounts to bypass Rate Limits.
*   **Smart Fallback:** Automatically switches to a backup model or account if the primary one fails or hits a limit.
*   **Logging:** All requests and **Thinking Processes** are logged and visible via the Admin Panel.

### Installation & Connection

When you start Antimatter via `antimatter.exe webui`, the LLM Provider service automatically starts at `http://localhost:8045`.

#### General Settings

Use these settings in any OpenAI-compatible client:

*   **Base URL (Endpoint):** `http://localhost:8045/v1`
*   **API Key:**
    *   If `Auth Mode: Off`: You can write anything random (e.g., `sk-antimatter`).
    *   If `Auth Mode: Strict`: Use an `sk-mcp-...` key generated from the Admin Panel.

#### Application Examples

**1. Cursor / VS Code (AI Extensions)**
*   **URL:** `http://localhost:8045/v1`
*   **API Key:** `sk-dummy` (or your key)
*   **Model Name:** `gemini-2.0-flash-exp`

**2. SillyTavern / Text Generation WebUI**
*   **API Type:** OpenAI (Chat Completions)
*   **API URL:** `http://localhost:8045/v1`
*   **Connect**: Click connect to fetch models.

**3. Python / Node.js SDK**

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8045/v1",
    api_key="none"
)

response = client.chat.completions.create(
    model="gemini-2.0-flash-exp",
    messages=[{"role": "user", "content": "Hello!"}]
)
print(response.choices[0].message.content)
```

#### Global System Prompt

You can configure a **Global System Prompt** via `settings.yaml` or the Admin Panel. This instruction is silently injected (prepended) into **all** requests made in Provider mode.

Example:
> "You are a helpful assistant that always responds in JSON format."

When set, all connected apps (Cursor, scripts, etc.) will adhere to this rule implicitly.

---

## TÃ¼rkÃ§e ğŸ‡¹ğŸ‡·

# LLM Provider Modu (Model SaÄŸlayÄ±cÄ±)

**LLM Provider** modu, Antimatter'Ä±n standart bir **OpenAI-Compatible API** (OpenAI Uyumlu API) olarak Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar. Bu modda Antimatter, kendisine gelen sohbet isteklerini karÅŸÄ±lar, arka planda Google Gemini API'sini kullanarak iÅŸler ve cevabÄ± OpenAI formatÄ±nda geri dÃ¶ndÃ¼rÃ¼r.

Bu sayede, Google Gemini'yi desteklemeyen ancak OpenAI destekleyen yÃ¼zlerce uygulama ile Gemini modellerini kullanabilirsiniz.

### Ã–zellikler

*   **OpenAI UyumluluÄŸu:** `/v1/chat/completions` ve `/v1/models` uÃ§ noktalarÄ±nÄ± saÄŸlar.
*   **Hesap Havuzu (Account Rotation):** Birden fazla Google hesabÄ± ekleyerek hÄ±z limitlerini (Rate Limits) aÅŸmanÄ±zÄ± saÄŸlar.
*   **AkÄ±llÄ± Yedekleme (Fallback):** Bir model hata verirse veya limit dolarsa otomatik olarak yedek modele veya hesaba geÃ§er.
*   **Loglama:** TÃ¼m istekler ve dÃ¼ÅŸÃ¼nce sÃ¼reÃ§leri (Thinking Process) kaydedilir ve Admin Paneli'nden izlenebilir.

### Kurulum ve BaÄŸlantÄ±

Antimatter'Ä± `webui` modunda baÅŸlattÄ±ÄŸÄ±nÄ±zda (`antimatter.exe webui`), LLM Provider servisi otomatik olarak `http://localhost:8045` adresinde Ã§alÄ±ÅŸmaya baÅŸlar.

#### Genel Ayarlar

OpenAI uyumlu herhangi bir istemcide (Client) ÅŸu ayarlarÄ± kullanÄ±n:

*   **Base URL (Endpoint):** `http://localhost:8045/v1`
*   **API Key:**
    *   EÄŸer `Auth Mode: Off` ise: Rastgele bir ÅŸey yazabilirsiniz (Ã¶rn: `sk-antimatter`).
    *   EÄŸer `Auth Mode: Strict` ise: Admin panelinden oluÅŸturduÄŸunuz `sk-mcp-...` ÅŸeklindeki anahtarÄ± girin.

#### Uygulama BazlÄ± Kurulumlar

**1. Cursor / VS Code (AI Eklentileri)**
*   **URL:** `http://localhost:8045/v1`
*   **API Key:** `sk-bos-gec` (veya kendi keyiniz)
*   **Model AdÄ±:** `gemini-2.0-flash-exp` (veya kullanmak istediÄŸiniz model)

**2. SillyTavern / Text Generation WebUI**
*   **API Type:** OpenAI (Chat Completions)
*   **API URL:** `http://localhost:8045/v1`
*   **API Key:** `1234`
*   **Connect** butonuna bastÄ±ÄŸÄ±nÄ±zda modeller listelenecektir.

**3. Python / Node.js ile KullanÄ±m**

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8045/v1",
    api_key="gerek-yok"
)

response = client.chat.completions.create(
    model="gemini-2.0-flash-exp",
    messages=[{"role": "user", "content": "Merhaba!"}]
)

print(response.choices[0].message.content)
```

#### Global System Prompt

`settings.yaml` veya Admin Paneli Ã¼zerinden **Global System Prompt** ayarlayabilirsiniz. Bu komut, PROVIDER modunda yapÄ±lan **tÃ¼m** isteklere (istemci ne gÃ¶nderirse gÃ¶ndersin) gizlice eklenir.

Ã–rneÄŸin:
> "Sen her zaman TÃ¼rkÃ§e ve resmi bir dille yanÄ±t veren bir asistansÄ±n."

Bunu ayarladÄ±ÄŸÄ±nÄ±zda, baÄŸlanan tÃ¼m uygulamalar (Cursor, SillyTavern vb.) bu kurala uyacaktÄ±r.
